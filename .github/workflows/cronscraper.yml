name: cronscraper

on:
  schedule:
    - cron: '45 21 * * *'


jobs:
  cronscrape:
    runs-on: ubuntu-latest
    container: python:3.7
    steps:
      - name: Checkout master
        uses: actions/checkout@v2
        with:
          ref: 'master'
          path: 'master_branch/'
      - name: Install dependencies
        run: |
          cd master_branch
          pip install -r requirements.txt
      - name: Checkout data
        uses: actions/checkout@v2
        with:
          ref: 'data'
          path: 'data_branch/'
      - name: Scrape
        run: |
          SCRAPE_DATETIME=$(date +'%Y-%m-%dT%T')
          SCRAPE_DATE=$(date +'%Y-%m-%d')
          echo $SCRAPE_DATETIME > SCRAPE_DATETIME.txt
          echo $SCRAPE_DATE > SCRAPE_DATE.txt
          cd master_branch
          python scrape.py ../data_branch $SCRAPE_DATETIME
      - name: Push changes
        run: |
          SCRAPE_DATETIME=$(cat SCRAPE_DATETIME.txt)
          SCRAPE_DATE=$(cat SCRAPE_DATE.txt)
          cd data_branch
          REPO="https://${GITHUB_ACTOR}:${{ secrets.TOKEN }}@github.com/${GITHUB_REPOSITORY}.git"
          echo $REPO
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add .
          git commit -m "scrape $SCRAPE_DATETIME" --date $SCRAPE_DATETIME
          git tag $SCRAPE_DATE
          git push "${REPO}"
          git push "${REPO}" $SCRAPE_DATE -f
