name: cronarchiver

on:
  schedule:
    - cron: '15 17 * * *'
  push:
    branches:
      - master


jobs:
  scrape:
    runs-on: ubuntu-latest
    container: python:3.7
    steps:
      - uses: webfactory/ssh-agent@v0.2.0
        with:
          ssh-private-key: ${{ secrets.SSH_KEY }}
      - name: Authenticate
        run: |
          ssh -T git@github.com
          REPO="git@github.com/${GITHUB_REPOSITORY}.git"
          git clone $REPO --dry-run

      - name: Checkout master
        uses: actions/checkout@v2
        with:
          ref: 'master'
          path: 'master_branch/'
      - name: Install dependencies
        run: |
          cd master_branch
          pip install -r requirements.txt
      - name: Checkout data
        uses: actions/checkout@v2
        with:
          ref: 'data'
          path: 'data_branch/'
      - name: Scrape
        run: |
          SCRAPE_DATETIME=$(date +'%Y-%m-%dT%T')
          SCRAPE_DATE=$(date +'%Y-%m-%d')
          echo $SCRAPE_DATETIME > SCRAPE_DATETIME.txt
          echo $SCRAPE_DATE > SCRAPE_DATE.txt
          cd master_branch
          python scrape.py ../data_branch $SCRAPE_DATETIME
      - name: Push changes
        run: |
          SCRAPE_DATETIME=$(cat SCRAPE_DATETIME.txt)
          SCRAPE_DATE=$(cat SCRAPE_DATE.txt)
          cd data_branch
          REPO="git@github.com/${GITHUB_REPOSITORY}.git"
          echo $REPO
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add .
          git commit -m "scrape $SCRAPE_DATETIME" --date $SCRAPE_DATETIME
          git tag $SCRAPE_DATE
          git push "${REPO}"
          git push "${REPO}" $SCRAPE_DATE -f
